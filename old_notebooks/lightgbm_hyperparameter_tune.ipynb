{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\alvin\\anaconda3\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\alvin\\anaconda3\\lib\\site-packages (0.37.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F0bdYybyzm2i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ltP548wxzxcZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nlpaug in c:\\users\\alvin\\anaconda3\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: gdown>=4.0.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from nlpaug) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from nlpaug) (2.28.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from nlpaug) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from nlpaug) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2022.9.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.3.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YoMrTyDyzxfA"
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9w00zltDzxhd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textattack in c:\\users\\alvin\\anaconda3\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: transformers>=4.21.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (4.26.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (3.6.0)\n",
      "Requirement already satisfied: num2words in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.5.12)\n",
      "Requirement already satisfied: bert-score>=0.3.5 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.3.13)\n",
      "Requirement already satisfied: language-tool-python in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (2.7.1)\n",
      "Requirement already satisfied: datasets==2.4.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.9.1)\n",
      "Requirement already satisfied: pinyin==0.4.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.4.4)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (8.0.4)\n",
      "Requirement already satisfied: word2number in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (3.7)\n",
      "Requirement already satisfied: flair in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.11.3)\n",
      "Requirement already satisfied: lru-dict in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.1.8)\n",
      "Requirement already satisfied: editdistance in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.6.2)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.13.1)\n",
      "Requirement already satisfied: pycld2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.41)\n",
      "Requirement already satisfied: jieba in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.42.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (9.1.0)\n",
      "Requirement already satisfied: OpenHowNet in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (2.0)\n",
      "Requirement already satisfied: terminaltables in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (3.1.10)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (4.64.1)\n",
      "Requirement already satisfied: lemminflect in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (0.2.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.21.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from textattack) (1.7.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (21.3)\n",
      "Requirement already satisfied: dill<0.3.6 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (0.3.5.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (0.18.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (3.2.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (11.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (2022.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (0.13.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (0.70.13)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from datasets==2.4.0->textattack) (3.8.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from bert-score>=0.3.5->textattack) (3.5.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from click<8.1.0->textattack) (0.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->textattack) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack) (4.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from transformers>=4.21.0->textattack) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from transformers>=4.21.0->textattack) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from transformers>=4.21.0->textattack) (6.0)\n",
      "Requirement already satisfied: ftfy in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (6.1.1)\n",
      "Requirement already satisfied: langdetect in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (1.0.9)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (1.5.11)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.1.95)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (1.2.13)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.3.4)\n",
      "Requirement already satisfied: hyperopt>=0.2.7 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.2.7)\n",
      "Requirement already satisfied: tabulate in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.8.10)\n",
      "Requirement already satisfied: wikipedia-api in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.5.8)\n",
      "Requirement already satisfied: lxml in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (4.9.1)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.3)\n",
      "Requirement already satisfied: conllu>=4.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (4.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (1.0.2)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (4.6.5)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (2.1.0)\n",
      "Requirement already satisfied: gdown==4.4.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (4.4.0)\n",
      "Requirement already satisfied: janome in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (0.4.2)\n",
      "Requirement already satisfied: pptree in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (3.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from flair->textattack) (4.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gdown==4.4.0->flair->textattack) (4.11.1)\n",
      "Requirement already satisfied: six in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gdown==4.4.0->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from nltk->textattack) (1.1.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from num2words->textattack) (0.6.2)\n",
      "Requirement already satisfied: anytree in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from OpenHowNet->textattack) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from OpenHowNet->textattack) (67.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair->textattack) (1.14.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair->textattack) (5.2.1)\n",
      "Requirement already satisfied: future in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair->textattack) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair->textattack) (2.8.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair->textattack) (2.0.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair->textattack) (0.10.9.7)\n",
      "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from konoha<5.0.0,>=4.0.0->flair->textattack) (3.10.1)\n",
      "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from konoha<5.0.0,>=4.0.0->flair->textattack) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (1.26.11)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair->textattack) (2.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.4.0->textattack) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.4.0->textattack) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.4.0->textattack) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.4.0->textattack) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.4.0->textattack) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.4.0->textattack) (1.3.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from ftfy->flair->textattack) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair->textattack) (3.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alvin\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown==4.4.0->flair->textattack) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHlYneeSzxjt",
    "outputId": "f8c161ce-bae9-49c5-805a-0d0f721dae8f"
   },
   "outputs": [],
   "source": [
    "from textattack.augmentation import EmbeddingAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVw8al93z32j",
    "outputId": "5ffb21eb-47b5-454d-dbe0-00a7cb710a77"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "T7k-lcJgW0io"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Likes</th>\n",
       "      <th>NFT</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>vader</th>\n",
       "      <th>textblob</th>\n",
       "      <th>Polarity (Reviewer 1)</th>\n",
       "      <th>Polarity (Reviewer 2)\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#27894...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üê≥1 Mutant Ape Yacht Club bought for Œû15.377\\n\\...</td>\n",
       "      <td>mutant ape yacht club bought floor h chg floor...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#77 so...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#23452...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>Mutant Ape Yacht Club #27908 sold for 17 ETH (...</td>\n",
       "      <td>mutant ape yacht club sold eth nft collection ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime  Quarter  Likes                    NFT  \\\n",
       "0  2022-06-27       22      2  Mutant Ape Yacht Club   \n",
       "1  2023-02-11       31      2  Mutant Ape Yacht Club   \n",
       "2  2022-12-30       24      0  Mutant Ape Yacht Club   \n",
       "3  2022-12-29       24      0  Mutant Ape Yacht Club   \n",
       "4  2022-12-29       24      1  Mutant Ape Yacht Club   \n",
       "\n",
       "                                                Text  \\\n",
       "0  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#27894...   \n",
       "1  üê≥1 Mutant Ape Yacht Club bought for Œû15.377\\n\\...   \n",
       "2  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#77 so...   \n",
       "3  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#23452...   \n",
       "4  Mutant Ape Yacht Club #27908 sold for 17 ETH (...   \n",
       "\n",
       "                                          Clean Text vader textblob  \\\n",
       "0          mutant ape yacht club mayc nft sold eth k   neu      neu   \n",
       "1  mutant ape yacht club bought floor h chg floor...   neu      neu   \n",
       "2          mutant ape yacht club mayc nft sold eth k   neu      neu   \n",
       "3          mutant ape yacht club mayc nft sold eth k   neu      neu   \n",
       "4  mutant ape yacht club sold eth nft collection ...   neu      neu   \n",
       "\n",
       "  Polarity (Reviewer 1) Polarity (Reviewer 2)\\r  \n",
       "0                   pos                   pos\\r  \n",
       "1                   pos                   pos\\r  \n",
       "2                   pos                   pos\\r  \n",
       "3                   pos                   pos\\r  \n",
       "4                   pos                   pos\\r  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('label_dataset.csv', lineterminator='\\n')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "X7isxrdkW0io"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Likes</th>\n",
       "      <th>NFT</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>vader</th>\n",
       "      <th>textblob</th>\n",
       "      <th>label</th>\n",
       "      <th>Polarity (Reviewer 2)\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#27894...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üê≥1 Mutant Ape Yacht Club bought for Œû15.377\\n\\...</td>\n",
       "      <td>mutant ape yacht club bought floor h chg floor...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#77 so...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#23452...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>Mutant Ape Yacht Club #27908 sold for 17 ETH (...</td>\n",
       "      <td>mutant ape yacht club sold eth nft collection ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime  Quarter  Likes                    NFT  \\\n",
       "0  2022-06-27       22      2  Mutant Ape Yacht Club   \n",
       "1  2023-02-11       31      2  Mutant Ape Yacht Club   \n",
       "2  2022-12-30       24      0  Mutant Ape Yacht Club   \n",
       "3  2022-12-29       24      0  Mutant Ape Yacht Club   \n",
       "4  2022-12-29       24      1  Mutant Ape Yacht Club   \n",
       "\n",
       "                                                Text  \\\n",
       "0  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#27894...   \n",
       "1  üê≥1 Mutant Ape Yacht Club bought for Œû15.377\\n\\...   \n",
       "2  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#77 so...   \n",
       "3  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#23452...   \n",
       "4  Mutant Ape Yacht Club #27908 sold for 17 ETH (...   \n",
       "\n",
       "                                          Clean Text vader textblob label  \\\n",
       "0          mutant ape yacht club mayc nft sold eth k   neu      neu   pos   \n",
       "1  mutant ape yacht club bought floor h chg floor...   neu      neu   pos   \n",
       "2          mutant ape yacht club mayc nft sold eth k   neu      neu   pos   \n",
       "3          mutant ape yacht club mayc nft sold eth k   neu      neu   pos   \n",
       "4  mutant ape yacht club sold eth nft collection ...   neu      neu   pos   \n",
       "\n",
       "  Polarity (Reviewer 2)\\r  \n",
       "0                   pos\\r  \n",
       "1                   pos\\r  \n",
       "2                   pos\\r  \n",
       "3                   pos\\r  \n",
       "4                   pos\\r  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'Polarity (Reviewer 1)':'label'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ILeWpfPmQGvi"
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace('neg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9shnCakaQG27"
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace('pos',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Oh2SvmYPQG9Z"
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace('neu',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "g_TyvzSpWBgI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Likes</th>\n",
       "      <th>NFT</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>vader</th>\n",
       "      <th>textblob</th>\n",
       "      <th>label</th>\n",
       "      <th>Polarity (Reviewer 2)\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#27894...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üê≥1 Mutant Ape Yacht Club bought for Œû15.377\\n\\...</td>\n",
       "      <td>mutant ape yacht club bought floor h chg floor...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#77 so...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#23452...</td>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutant Ape Yacht Club</td>\n",
       "      <td>Mutant Ape Yacht Club #27908 sold for 17 ETH (...</td>\n",
       "      <td>mutant ape yacht club sold eth nft collection ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime  Quarter  Likes                    NFT  \\\n",
       "0  2022-06-27       22      2  Mutant Ape Yacht Club   \n",
       "1  2023-02-11       31      2  Mutant Ape Yacht Club   \n",
       "2  2022-12-30       24      0  Mutant Ape Yacht Club   \n",
       "3  2022-12-29       24      0  Mutant Ape Yacht Club   \n",
       "4  2022-12-29       24      1  Mutant Ape Yacht Club   \n",
       "\n",
       "                                                Text  \\\n",
       "0  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#27894...   \n",
       "1  üê≥1 Mutant Ape Yacht Club bought for Œû15.377\\n\\...   \n",
       "2  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#77 so...   \n",
       "3  üß™ Mutant Ape Yacht Club | #MAYC #NFT\\n\\n#23452...   \n",
       "4  Mutant Ape Yacht Club #27908 sold for 17 ETH (...   \n",
       "\n",
       "                                          Clean Text vader textblob  label  \\\n",
       "0          mutant ape yacht club mayc nft sold eth k   neu      neu    1.0   \n",
       "1  mutant ape yacht club bought floor h chg floor...   neu      neu    1.0   \n",
       "2          mutant ape yacht club mayc nft sold eth k   neu      neu    1.0   \n",
       "3          mutant ape yacht club mayc nft sold eth k   neu      neu    1.0   \n",
       "4  mutant ape yacht club sold eth nft collection ...   neu      neu    1.0   \n",
       "\n",
       "  Polarity (Reviewer 2)\\r  \n",
       "0                   pos\\r  \n",
       "1                   pos\\r  \n",
       "2                   pos\\r  \n",
       "3                   pos\\r  \n",
       "4                   pos\\r  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ifkIE9d4W0io"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1053\n",
       "2.0     453\n",
       "0.0      95\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fItnkpZwW0io"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mutant ape yacht club bought floor h chg floor...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mutant ape yacht club mayc nft sold eth k</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mutant ape yacht club sold eth nft collection ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Clean Text  label\n",
       "0          mutant ape yacht club mayc nft sold eth k    1.0\n",
       "1  mutant ape yacht club bought floor h chg floor...    1.0\n",
       "2          mutant ape yacht club mayc nft sold eth k    1.0\n",
       "3          mutant ape yacht club mayc nft sold eth k    1.0\n",
       "4  mutant ape yacht club sold eth nft collection ...    1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Clean Text','label']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FP08YKs7W0io"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4KXT-9prW0ip"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rvnSO_pBW0ip"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R7z3Bfa1W0ip"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Clean Text'], df['label'], test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Lvp3lcV2W0ip"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    848\n",
       "2.0    353\n",
       "0.0     79\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yIZXBbOlW0ip"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 1,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BAnK1h3pW0ip"
   },
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ojs2yqvcCMvL"
   },
   "outputs": [],
   "source": [
    "embed_aug = EmbeddingAugmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vcKNRe10CMvM"
   },
   "outputs": [],
   "source": [
    "augmented_sentences=[]\n",
    "augmented_sentences_labels=[]\n",
    "for i in X_train.index:\n",
    "  if y_train[i]==0:\n",
    "    temps3=embed_aug.augment(X_train[i])\n",
    "    for sent in temps3:\n",
    "      augmented_sentences.append(sent)\n",
    "      augmented_sentences_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2B-ObnOECMvL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1359,)\n",
      "(1359,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\AppData\\Local\\Temp\\ipykernel_2468\\31741503.py:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(pd.Series(augmented_sentences),ignore_index=True)\n",
      "C:\\Users\\Alvin\\AppData\\Local\\Temp\\ipykernel_2468\\31741503.py:2: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train=y_train.append(pd.Series(augmented_sentences_labels),ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.append(pd.Series(augmented_sentences),ignore_index=True)\n",
    "y_train=y_train.append(pd.Series(augmented_sentences_labels),ignore_index=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7zQrI1iQCMvL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    848\n",
       "2.0    353\n",
       "0.0    158\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "TM5aXTmmCMvL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alvin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Alvin\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet',aug_max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fngh7ZUaCMvL"
   },
   "outputs": [],
   "source": [
    "augmented_sentences=[]\n",
    "augmented_sentences_labels=[]\n",
    "for i in X_train.index:\n",
    "  if y_train[i]==0:\n",
    "    temps1=aug.augment(X_train[i],n=3)\n",
    "    for sent in temps1:\n",
    "      augmented_sentences.append(sent)\n",
    "      augmented_sentences_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "r906bi1RCMvM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1833,)\n",
      "(1833,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\AppData\\Local\\Temp\\ipykernel_2468\\31741503.py:1: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train=X_train.append(pd.Series(augmented_sentences),ignore_index=True)\n",
      "C:\\Users\\Alvin\\AppData\\Local\\Temp\\ipykernel_2468\\31741503.py:2: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train=y_train.append(pd.Series(augmented_sentences_labels),ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.append(pd.Series(augmented_sentences),ignore_index=True)\n",
    "y_train=y_train.append(pd.Series(augmented_sentences_labels),ignore_index=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "guRz2H6LCMvM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    848\n",
       "0.0    632\n",
       "2.0    353\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "NI9LGatoCMvM"
   },
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0JV32rbIrU7",
    "outputId": "c8af3a2b-6c19-46d5-8a59-956830de98c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': 'warn',\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_classifier = LGBMClassifier()\n",
    "\n",
    "LGB_classifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "04sO1ruGCMvM"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "LGB_classifier = LGBMClassifier(seed=0).fit(X_train_vectorized,y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "time_linear_train = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "z1Lmk6Z_PgaK"
   },
   "outputs": [],
   "source": [
    "y_pred=LGB_classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Xk8S6s1-CMvM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 560.315035s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time: %fs\" % (time_linear_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "RywKs3EfCMvM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193146417445483\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "K6QrPWtTCMvN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.50      0.50        16\n",
      "         1.0       0.85      0.91      0.88       205\n",
      "         2.0       0.81      0.69      0.75       100\n",
      "\n",
      "    accuracy                           0.82       321\n",
      "   macro avg       0.72      0.70      0.71       321\n",
      "weighted avg       0.82      0.82      0.82       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "5CtRqi03Nnf5"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "F0LMmWwYz37T"
   },
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "param_grid = { \n",
    "    \"learning_rate\": [0.1, 0.01],\n",
    "    \"max_depth\": [3, 5, 7, 9],\n",
    "    \"num_leaves\": [25, 50, 75, 100],\n",
    "    \"feature_fraction\": [0.3, 0.5, 0.8],\n",
    "    \"bagging_fraction\": [0.3, 0.5, 0.8],\n",
    "    \"min_child_samples\": [10, 30, 50]\n",
    "    }\n",
    "# Set up score\n",
    "scoring = ['f1']\n",
    "# Set up the k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "AFeP9mNDz39w",
    "outputId": "7d939d48-0cd8-4ca0-931e-0e8f3d743e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n",
      "The best score is nan\n",
      "The best hyperparameters are {'bagging_fraction': 0.3, 'feature_fraction': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 10, 'num_leaves': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define grid search\n",
    "grid_search = GridSearchCV(estimator=LGB_classifier, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring=scoring, \n",
    "                           refit='f1', \n",
    "                           n_jobs=-1, \n",
    "                           cv=kfold, \n",
    "                           verbose=0)\n",
    "# Fit grid search\n",
    "grid_result = grid_search.fit(X_train_vectorized,y_train)\n",
    "# Print grid search summary\n",
    "grid_result\n",
    "# Print the best score and the corresponding hyperparameters\n",
    "print(f'The best score is {grid_result.best_score_:.4f}')\n",
    "#print('The best score standard deviation is', round(grid_result.cv_results_['std_test_recall'][grid_result.best_index_], 4))\n",
    "print(f'The best hyperparameters are {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "DjUQQ6Ahz3_t"
   },
   "outputs": [],
   "source": [
    "# Make prediction using the best model\n",
    "grid_predict = grid_search.predict(X_test_vectorized)\n",
    "# Get predicted probabilities\n",
    "#grid_predict_prob = grid_search.predict_proba(X_test_vectorized)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "y4AWNFH5z4CP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193146417445483\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "slsiMi1wzxmB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.50      0.50        16\n",
      "         1.0       0.85      0.91      0.88       205\n",
      "         2.0       0.81      0.69      0.75       100\n",
      "\n",
      "    accuracy                           0.82       321\n",
      "   macro avg       0.72      0.70      0.71       321\n",
      "weighted avg       0.82      0.82      0.82       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu2dap4SzxoK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOb6HAbwzxqr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
